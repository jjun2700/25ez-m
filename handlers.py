import streamlit as st
import pandas as pd
from db_config import get_connection, IS_STREAMLIT_CLOUD

# í•¸ë“¤ëŸ¬ í•¨ìˆ˜ ì •ì˜
# ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¥¸ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ í¬í•¨
from views import show_pn_details

def handle_pn_search(conn, pn_input):
    # PN ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ì‚¬ìš©ìê°€ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ ìƒì„¸ì •ë³´ í‘œì‹œ
    if IS_STREAMLIT_CLOUD:
        query = "SELECT DISTINCT PN_l AS PN FROM M8_LOT WHERE PN_l LIKE %s ORDER BY PN"
    else:
        query = "SELECT DISTINCT PN_l AS PN FROM M8_LOT WHERE PN_l LIKE ? ORDER BY PN"

    df = pd.read_sql(query, conn, params=[pn_input + '%'])

    if df.empty:
        st.warning("ì¡°ê±´ì— ë§ëŠ” PNì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²€ìƒ‰ ê²°ê³¼ê°€ 1ê°œì¸ ê²½ìš° ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ìƒì„¸ì •ë³´ í‘œì‹œ
    if len(df) == 1:
        selected_pn = df.iloc[0]["PN"]
#        st.success(f"[{selected_pn}] PNì„ ìë™ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        st.markdown(f"#### ğŸ¯ **----- ì œí’ˆ ìƒì„¸ ì •ë³´ [{selected_pn}] -----**")
        show_pn_details(conn, selected_pn)
        return

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° ì„ íƒ UI ì œê³µ
    df["ì„ íƒ"] = False
    st.subheader("âœ… PN ë¦¬ìŠ¤íŠ¸ (í•˜ë‚˜ë§Œ ì„ íƒ ê°€ëŠ¥)", divider=True)
    
    # ì„ íƒ ìƒíƒœë¥¼ ìœ„í•œ unique key ìƒì„±
    table_key = f"pn_table_{hash(pn_input)}"
    edited_df = st.data_editor(df, use_container_width=True, num_rows="fixed", key=table_key)
    selected_rows = edited_df[edited_df["ì„ íƒ"] == True]

    if len(selected_rows) > 1:
        st.error("âš ï¸ í•˜ë‚˜ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    elif len(selected_rows) == 1:
        selected_pn = selected_rows.iloc[0]["PN"]
        
        # ì„ íƒí•œ PNì„ session_stateì— ì €ì¥
        st.session_state.selected_pn_from_search = selected_pn
        st.session_state.pn_search_completed = True
        st.session_state.show_details_immediately = True  # ì¦‰ì‹œ ìƒì„¸í™”ë©´ í‘œì‹œ í”Œë˜ê·¸
        
        st.success(f"[{selected_pn}] PNì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤.")
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì…ë ¥ì°½ ì—…ë°ì´íŠ¸ ë° ìƒì„¸í™”ë©´ í‘œì‹œ
        st.rerun()
    else:
        st.info("â†’ í•˜ë‚˜ì˜ PNì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")

def handle_order_going_search(conn):
    # ì „ì²´ ë¯¸ë‚© ìˆ˜ì£¼ ë¦¬ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ê³  ì‚¬ìš©ìê°€ ì„ íƒí•œ PNìœ¼ë¡œ ì „í™˜
    query = '''
        SELECT DDeadline_g AS ë‚©ê¸°ì¼, PN_g AS PN, QResidual_g AS ë¯¸ë‚©ìˆ˜ëŸ‰, Customer_g AS ê³ ê°ëª…, TypeOut_g AS êµ¬ë¶„, PKG_g AS íŒ¨í‚¤ì§€
        FROM M8_Order_Going
        ORDER BY ë‚©ê¸°ì¼
    '''
    df = pd.read_sql(query, conn)
    pn_index = df.columns.get_loc("PN") + 1
    df.insert(pn_index, "ì„ íƒ", False)

    st.subheader("ğŸ›’ ë¯¸ë‚© ìˆ˜ì£¼ í˜„í™©", divider=True)
    edited_df = st.data_editor(df, use_container_width=True, num_rows="fixed", key="order_table")
    selected_rows = edited_df[edited_df["ì„ íƒ"] == True]

    if len(selected_rows) < 1:
        st.info("â†’ í•˜ë‚˜ì˜ PNì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        st.session_state.selected_pn_from_search = selected_rows.iloc[0]["PN"]
        st.session_state.search_mode = "pn_search"
        st.rerun()

def handle_wip_search(conn):
    # ì „ì²´ ì¬ê³µ ë¦¬ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ê³  ì‚¬ìš©ìê°€ ì„ íƒí•œ PNìœ¼ë¡œ ì „í™˜
    query = '''
        SELECT PN_w AS PN, LN_w AS LN, SWIP_w AS ê³µì •, QWFR_w AS ì›¨ì´í¼, QHMG_w AS ë°˜ì œí’ˆ, ND_w As NetDie, EYield_w As ì˜ˆìƒìˆ˜ìœ¨, QGoods_w As ì˜ˆìƒì–‘í’ˆ, NDate_Do_w AS ì‘ì—…ì¼
        FROM M8_LOT_WIP
        ORDER BY ì‘ì—…ì¼
    '''
    df = pd.read_sql(query, conn)
    pn_index = df.columns.get_loc("PN") + 1
    df.insert(pn_index, "ì„ íƒ", False)

    st.subheader("ğŸ“¦ ì¬ê³µ í˜„í™©", divider=True)
    edited_df = st.data_editor(df, use_container_width=True, num_rows="fixed", key="wip_table")
    selected_rows = edited_df[edited_df["ì„ íƒ"] == True]

    if len(selected_rows) < 1:
        st.info("â†’ í•˜ë‚˜ì˜ PNì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        st.session_state.selected_pn_from_search = selected_rows.iloc[0]["PN"]
        st.session_state.search_mode = "pn_search"
        st.rerun()

def handle_excess_quantity_search(conn):
    """ì´ˆê³¼ìˆ˜ëŸ‰ ê²€ìƒ‰ - SQL Serverìš© JOIN ìµœì í™” ë²„ì „"""
    
    if IS_STREAMLIT_CLOUD:
        # Streamlit Cloudìš© ì¿¼ë¦¬ (MySQL/PostgreSQL ìŠ¤íƒ€ì¼)
        query = '''
        SELECT 
            o.PN,
            COALESCE(s.stock_total, 0) as stock_total,
            COALESCE(w.wip_total, 0) as wip_total,
            o.order_g_total,
            COALESCE(c.customer_name, '-') as customer_name,
            (COALESCE(s.stock_total, 0) + COALESCE(w.wip_total, 0) - o.order_g_total) as excess_quantity
        FROM (
            SELECT 
                PN_g AS PN,
                SUM(QResidual_g) as order_g_total
            FROM M8_Order_Going
            GROUP BY PN_g
        ) o
        LEFT JOIN (
            SELECT 
                PN_s AS PN,
                SUM(Qty_s) as stock_total
            FROM M8_MG_Stock
            GROUP BY PN_s
        ) s ON o.PN = s.PN
        LEFT JOIN (
            SELECT 
                PN_w AS PN,
                SUM(QGoods_w) as wip_total
            FROM M8_LOT_WIP
            GROUP BY PN_w
        ) w ON o.PN = w.PN
        LEFT JOIN (
            SELECT DISTINCT
                PN_g AS PN,
                FIRST_VALUE(Customer_g) OVER (PARTITION BY PN_g ORDER BY DDeadline_g ASC) as customer_name
            FROM M8_Order_Going
        ) c ON o.PN = c.PN
        ORDER BY excess_quantity ASC
        '''
    else:
        # SQL Serverìš© ì¿¼ë¦¬
        query = '''
        SELECT 
            o.PN,
            COALESCE(s.stock_total, 0) as stock_total,
            COALESCE(w.wip_total, 0) as wip_total,
            o.order_g_total,
            COALESCE(c.customer_name, '-') as customer_name,
            (COALESCE(s.stock_total, 0) + COALESCE(w.wip_total, 0) - o.order_g_total) as excess_quantity
        FROM (
            SELECT 
                PN_g AS PN,
                SUM(QResidual_g) as order_g_total
            FROM M8_Order_Going
            GROUP BY PN_g
        ) o
        LEFT JOIN (
            SELECT 
                PN_s AS PN,
                SUM(Qty_s) as stock_total
            FROM M8_MG_Stock
            GROUP BY PN_s
        ) s ON o.PN = s.PN
        LEFT JOIN (
            SELECT 
                PN_w AS PN,
                SUM(QGoods_w) as wip_total
            FROM M8_LOT_WIP
            GROUP BY PN_w
        ) w ON o.PN = w.PN
        LEFT JOIN (
            SELECT DISTINCT
                PN_g AS PN,
                FIRST_VALUE(Customer_g) OVER (PARTITION BY PN_g ORDER BY DDeadline_g ASC) as customer_name
            FROM M8_Order_Going
        ) c ON o.PN = c.PN
        ORDER BY excess_quantity ASC
        '''
    
    try:
        # í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ëª¨ë“  ë°ì´í„° ì¡°íšŒ
        df_result = pd.read_sql(query, conn)
        
        if df_result.empty:
            st.warning("ë¯¸ë‚©ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ ë°ì´í„° ì •ë¦¬
        result_data = []
        for _, row in df_result.iterrows():
            result_data.append({
                'PN': row['PN'],
                'ì„ íƒ': False,
                'ì´ˆê³¼ìˆ˜ëŸ‰': int(row['excess_quantity']),
                'ê³ ê°ëª…': row['customer_name'] if pd.notna(row['customer_name']) else "-",
                'ì¬ê³ í•©ê³„': int(row['stock_total']) if pd.notna(row['stock_total']) else 0,
                'ì¬ê³µí•©ê³„': int(row['wip_total']) if pd.notna(row['wip_total']) else 0,
                'ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„': int(row['order_g_total']) if pd.notna(row['order_g_total']) else 0
            })
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(result_data)
        
        if df.empty:
            st.warning("ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        
        # ê¸°ì¡´ for ë¬¸ ë°©ì‹ìœ¼ë¡œ fallback
        handle_excess_quantity_search_fallback(conn)
        return
    
    # ë‚˜ë¨¸ì§€ UI ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼...
    st.subheader("ğŸ“Š ì´ˆê³¼ ìˆ˜ëŸ‰ í˜„í™©", divider=True)
    
    # ìš”ì•½ ì •ë³´
    total_negative = len(df[df['ì´ˆê³¼ìˆ˜ëŸ‰'] < 0])
    total_positive = len(df[df['ì´ˆê³¼ìˆ˜ëŸ‰'] >= 0])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì „ì²´ PN ìˆ˜", len(df))
    with col2:
        st.metric("ì¶©ë¶„ PN ìˆ˜", total_positive)
    with col3:
        st.markdown(
            f"""
            <div style="font-size: 0.875rem; color: #666; margin-bottom: 0.25rem;">ë¶€ì¡± PN ìˆ˜</div>
            <div style="font-size: 2rem; font-weight: 600; color: #ff4b4b;">{total_negative}</div>
            """,
            unsafe_allow_html=True
        )

    # ì´ˆê³¼ìˆ˜ëŸ‰ì— ë”°ë¥¸ ì‹œê°ì  í‘œì‹œ
    def format_excess_quantity(value):
        if value < -1000:
            return f"ğŸ”´ {value:,}"
        elif value < -100:
            return f"ğŸŸ  {value:,}"
        elif value < 0:
            return f"ğŸŸ¡ {value:,}"
        elif value < 10:
            return f"âšª {value:,}"
        else:
            return f"ğŸŸ¢ {value:,}"
    
    # í‘œì‹œìš© ì»¬ëŸ¼ ì¶”ê°€
    df['ìƒíƒœ'] = df['ì´ˆê³¼ìˆ˜ëŸ‰'].apply(format_excess_quantity)
    
    # ë°ì´í„° ì—ë””í„°
    edited_df = st.data_editor(
        df, 
        use_container_width=True, 
        num_rows="fixed", 
        key="excess_quantity_table",
        column_config={
            "PN": st.column_config.TextColumn("PN", width="medium"),
            "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", width="small"),
            "ìƒíƒœ": st.column_config.TextColumn(
                "ì´ˆê³¼ìˆ˜ëŸ‰", 
                width="medium",
                help="ğŸ”´ë§¤ìš°ë¶€ì¡± ğŸŸ ë¶€ì¡± ğŸŸ¡ì•½ê°„ë¶€ì¡± âšªì•½ê°„ì—¬ìœ  ğŸŸ¢ì¶©ë¶„"
            ),
            "ì¬ê³ í•©ê³„": st.column_config.NumberColumn("ì¬ê³ í•©ê³„", format="%d"),
            "ì¬ê³µí•©ê³„": st.column_config.NumberColumn("ì¬ê³µí•©ê³„", format="%d"),
            "ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„": st.column_config.NumberColumn("ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„", format="%d")
        },
        column_order=["PN", "ì„ íƒ", "ìƒíƒœ", "ê³ ê°ëª…", "ì¬ê³ í•©ê³„", "ì¬ê³µí•©ê³„", "ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„"]
    )
    
    # ì„ íƒëœ í–‰ ì²˜ë¦¬
    selected_rows = edited_df[edited_df["ì„ íƒ"] == True]
    
    if len(selected_rows) > 1:
        st.error("âš ï¸ í•˜ë‚˜ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    elif len(selected_rows) == 1:
        selected_pn = selected_rows.iloc[0]["PN"]
        
        st.session_state.selected_pn_from_search = selected_pn
        st.session_state.pn_search_completed = True
        st.session_state.show_details_immediately = True
        
        st.success(f"[{selected_pn}] PNì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤.")
        st.rerun()
    else:
        st.info("â†’ ìƒì„¸ì •ë³´ë¥¼ ë³´ë ¤ë©´ í•˜ë‚˜ì˜ PNì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")


def handle_excess_quantity_search_fallback(conn):
    """ê¸°ì¡´ for ë¬¸ ë°©ì‹ (fallbackìš©)"""
    # ê¸°ì¡´ ì½”ë“œë¥¼ ì—¬ê¸°ì— ë³µì‚¬í•´ì„œ ì‚¬ìš©
    unique_pn_query = "SELECT DISTINCT PN_g AS PN FROM M8_Order_Going ORDER BY PN"
    unique_pns = pd.read_sql(unique_pn_query, conn)
    
    if unique_pns.empty:
        st.warning("ë¯¸ë‚©ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    result_data = []
    
    for _, row in unique_pns.iterrows():
        pn = row['PN']
        
        # ì¬ê³ í•©ê³„ ì¡°íšŒ
        if IS_STREAMLIT_CLOUD:
            stock_query = "SELECT COALESCE(SUM(Qty_s), 0) as stock_total FROM M8_MG_Stock WHERE PN_s = %s"
        else:
            stock_query = "SELECT COALESCE(SUM(Qty_s), 0) as stock_total FROM M8_MG_Stock WHERE PN_s = ?"
        
        stock_result = pd.read_sql(stock_query, conn, params=[pn])
        stock_total = stock_result.iloc[0]['stock_total'] if not stock_result.empty else 0
        
        # ì¬ê³µí•©ê³„ ì¡°íšŒ
        if IS_STREAMLIT_CLOUD:
            wip_query = "SELECT COALESCE(SUM(QGoods_w), 0) as wip_total FROM M8_LOT_WIP WHERE PN_w = %s"
        else:
            wip_query = "SELECT COALESCE(SUM(QGoods_w), 0) as wip_total FROM M8_LOT_WIP WHERE PN_w = ?"
        
        wip_result = pd.read_sql(wip_query, conn, params=[pn])
        wip_total = wip_result.iloc[0]['wip_total'] if not wip_result.empty else 0
        
        # ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„ ì¡°íšŒ
        if IS_STREAMLIT_CLOUD:
            order_query = "SELECT COALESCE(SUM(QResidual_g), 0) as order_g_total FROM M8_Order_Going WHERE PN_g = %s"
        else:
            order_query = "SELECT COALESCE(SUM(QResidual_g), 0) as order_g_total FROM M8_Order_Going WHERE PN_g = ?"
        
        order_result = pd.read_sql(order_query, conn, params=[pn])
        order_g_total = order_result.iloc[0]['order_g_total'] if not order_result.empty else 0
        
        # ê³ ê°ëª… ì¡°íšŒ
        if IS_STREAMLIT_CLOUD:
            customer_query = "SELECT Customer_g FROM M8_Order_Going WHERE PN_g = %s ORDER BY DDeadline_g ASC LIMIT 1"
        else:
            customer_query = "SELECT TOP 1 Customer_g FROM M8_Order_Going WHERE PN_g = ? ORDER BY DDeadline_g ASC"

        customer_result = pd.read_sql(customer_query, conn, params=[pn])
        customer_name = customer_result.iloc[0]['Customer_g'] if not customer_result.empty else "-"

        # ì´ˆê³¼ìˆ˜ëŸ‰ ê³„ì‚°
        excess_quantity = stock_total + wip_total - order_g_total
        
        result_data.append({
            'PN': pn,
            'ì„ íƒ': False,
            'ì´ˆê³¼ìˆ˜ëŸ‰': int(excess_quantity),
            'ê³ ê°ëª…': customer_name,
            'ì¬ê³ í•©ê³„': int(stock_total),
            'ì¬ê³µí•©ê³„': int(wip_total),
            'ë¯¸ë‚©ìˆ˜ì£¼í•©ê³„': int(order_g_total)
        })
    
    # ë‚˜ë¨¸ì§€ ì²˜ë¦¬ëŠ” ê¸°ì¡´ê³¼ ë™ì¼...
